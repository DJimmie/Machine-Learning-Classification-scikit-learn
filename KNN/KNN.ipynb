{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEAREST NEIGHBORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD THE DEPENDANCIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:46.640287Z",
     "start_time": "2019-06-19T02:22:45.839242Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:46.650288Z",
     "start_time": "2019-06-19T02:22:46.644288Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import set_printoptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib & Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:47.606343Z",
     "start_time": "2019-06-19T02:22:46.654288Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:47.787353Z",
     "start_time": "2019-06-19T02:22:47.610343Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## math & stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:47.798354Z",
     "start_time": "2019-06-19T02:22:47.791353Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:47.812354Z",
     "start_time": "2019-06-19T02:22:47.803354Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# sys.path.insert(0, \"C:\\\\Users\\\\Crystal\\\\Desktop\\\\Programs\\\\my-modules-and-libraries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notebook widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:47.823355Z",
     "start_time": "2019-06-19T02:22:47.816355Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import ipywidgets as widgets\n",
    "from IPython.core.interactiveshell import InteractiveShell  \n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:47.909360Z",
     "start_time": "2019-06-19T02:22:47.827355Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### KNN Classifier\n",
    "\n",
    "def KNN(k,X_train,y_train,X_test,y_test):\n",
    "    \"\"\"KNN algorithm\"\"\"\n",
    "    global classifier\n",
    "    \n",
    "    f1_scores=[]\n",
    "    accur=[]\n",
    "    preci=[]\n",
    "    recall=[]\n",
    "    for i in k:\n",
    "        \n",
    "        # Define KNN Model\n",
    "        classifier = KNeighborsClassifier(n_neighbors=i, weights='uniform', algorithm='auto',\n",
    "                                           leaf_size=30, p=3, metric='minkowski',metric_params=None)\n",
    "        # Fit Model\n",
    "        classifier.fit(X_train,y_train)\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        y_prob=classifier.predict_proba(X_test)\n",
    "        \n",
    "        y_prob=y_prob[:,1]\n",
    "        \n",
    "        f1,a,p,r=metrics(y_test, y_pred)\n",
    "\n",
    "        \n",
    "        \n",
    "        f1_scores.append(f1)\n",
    "        accur.append(a)\n",
    "        preci.append(p)\n",
    "        recall.append(r)\n",
    "        \n",
    "    print('\\n','f1_scores: ',f1_scores)\n",
    "    print('accuracy: ',accur)\n",
    "    \n",
    "    return f1_scores,accur,preci,recall,y_pred,y_prob\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:47.957363Z",
     "start_time": "2019-06-19T02:22:47.912360Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Evaluate Model\n",
    "\n",
    "def metrics(y_test, y_pred):\n",
    "    \"\"\"Confusion matrix and associated metrics\"\"\"\n",
    "    matrix = confusion_matrix(y_test, y_pred)\n",
    "    y_test=y_test.values.reshape(y_test.size)\n",
    "#     tn,fp,fn,tp=confusion_matrix(y_test, y_pred).ravel()\n",
    "    precision=precision_score(y_test,y_pred,average=None)\n",
    "    recall=recall_score(y_test,y_pred,average=None)\n",
    "    f1=f1_score(y_test,y_pred,average=None)\n",
    "    accuracy=accuracy_score(y_test,y_pred)\n",
    "#     print('Confusion matrix breakdown:',('tn:',tn,'fp:',fp,'fn:',fn,'tp:',tp),'\\n')\n",
    "    print('Confusion matrix:\\n', matrix)\n",
    "    confusion_matrix_plot(matrix)\n",
    "    print('Precision: When it predicts yes, how often is it correct?:',precision)\n",
    "    print('Recall.True Positive Rate: When it\\'s actually yes, how often does it predict yes?:',recall)\n",
    "    print('F1:score is the harmonic average of the precision and recall,:',f1)\n",
    "    print('Accuracy.Overall, how often is the classifier correct?: ',accuracy)\n",
    "    print('Misclassification Rate.Overall, how often is it wrong?: ',(1-accuracy))\n",
    "\n",
    "    return (f1,accuracy,precision,recall)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:48.027367Z",
     "start_time": "2019-06-19T02:22:47.961363Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_plot(matrix):\n",
    "    cm=matrix\n",
    "    print(classes)\n",
    "    fig, ax = plt.subplots()\n",
    "    cmap=plt.cm.Blues\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes,\n",
    "           yticklabels=classes,\n",
    "           title=\"confusion\",\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    normalize=False\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING: Replacing zeros where it is not a valid value for that feature.\n",
    "##### This done here by replacing the zero values with a NAN, then replacing the NAN with the average value for non-zero values in that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:48.046368Z",
     "start_time": "2019-06-19T02:22:48.031367Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replacing_zeros(dataset,the_headers):\n",
    "    \"\"\"Function used to remove zeros from numeric features when 0 is not practical\"\"\"\n",
    "\n",
    "    for header in the_headers:\n",
    "        dataset[header]=dataset[header].replace(0,np.nan)\n",
    "        mean=int(dataset[header].mean(skipna=True))\n",
    "        dataset[header]=dataset[header].replace(np.nan,mean)\n",
    "        \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING: Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:48.063369Z",
     "start_time": "2019-06-19T02:22:48.050368Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_the_dataset(dataset,input_headers,target_header):\n",
    "    \n",
    "    X=dataset[input_headers]\n",
    "    y=dataset[target_header]\n",
    "    \n",
    "    X.head()\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING: Quick look at the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:48.259380Z",
     "start_time": "2019-06-19T02:22:48.230378Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def quick_feature_view(X):\n",
    "    \n",
    "\n",
    "    # X.hist(bins=50,figsize=(15,15))\n",
    "    # X.plot(kind='hist',subplots=True,layout=(3,3),sharex=False, figsize=(15,15))\n",
    "\n",
    "    headers=X.columns.tolist()\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(headers), figsize=(20, 10))\n",
    "    print(headers)\n",
    "    for i,head in enumerate(headers,0):\n",
    "\n",
    "        axes[i].hist(x=X[head],bins=50,edgecolor='black')\n",
    "        axes[i].set(title=head)\n",
    "        axes[i].grid()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    X.plot(kind='density',subplots=True,layout=(3,3),sharex=False, figsize=(15,15))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING:Target Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:48.518395Z",
     "start_time": "2019-06-19T02:22:48.509394Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_summary(dataset,target_header):\n",
    "    \"\"\"PREPROCESSING:Target Summary\"\"\"\n",
    "    print(dataset.groupby(target_header).size())\n",
    "    print((dataset.groupby(target_header).size()/len(y)*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING:Train - Test Split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:48.930418Z",
     "start_time": "2019-06-19T02:22:48.921418Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_the_train_test_data(X,y,test_size,random_state):\n",
    "    \n",
    "    \"\"\"PREPROCESSING:Train - Test Split of the data\"\"\"\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X, y,test_size=test_size,random_state=random_state,shuffle=True)\n",
    "#     X_train.head()\n",
    "    \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:49.162432Z",
     "start_time": "2019-06-19T02:22:49.149431Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_scaling(X_train,X_test):\n",
    "    sc_X=StandardScaler()\n",
    "    X_train=sc_X.fit_transform(X=X_train,y=None)\n",
    "    X_test=sc_X.fit_transform(X=X_test,y=None)\n",
    "\n",
    "    print(sc_X.fit(X_train))\n",
    "    print(X_train[0:5])\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters:Choose a value of k by taking the sqrt of the number of data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:49.391445Z",
     "start_time": "2019-06-19T02:22:49.366443Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_k_value(y_test,list_or_single):\n",
    "    \n",
    "    y_test.size\n",
    "    \n",
    "    if (list_or_single.lower()=='s'):\n",
    "        k=round(math.sqrt(y_test.size))\n",
    "        \n",
    "        if (k%2==0):\n",
    "            k_list=[]\n",
    "            k_list.insert(0,k-1)\n",
    "            k_list.insert(1,k+1)\n",
    "            k=k_list\n",
    "    else:\n",
    "        k=[3,5,7,9,11,13,15,17,19,21]\n",
    "        \n",
    "    print ('Selected k value(s):\\n',k)\n",
    "    return k\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:49.734464Z",
     "start_time": "2019-06-19T02:22:49.586456Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_the_metrics(f1_scores,accur,preci,recall):\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20, 10),sharex='none')\n",
    "    axes[0,0].plot(k,f1_scores,marker='o')\n",
    "    axes[0,1].plot(k,accur,marker='o')\n",
    "    axes[0,0].set(title='F1 Score')\n",
    "    axes[0,1].set(title='Accuracy')\n",
    "    axes[0,0].set(xlabel='K value')\n",
    "    axes[0,1].set(xlabel='K value')\n",
    "#     axes[0,0].set(xlim=(3,21), ylim=(0,1))\n",
    "#     axes[0,1].set(xlim=(3,21), ylim=(0,1))\n",
    "    axes[0,0].set(xticks=range(3,23,2),yticks=np.arange(0,1.1,.1))\n",
    "    axes[0,1].set(xticks=range(3,23,2),yticks=np.arange(0,1.1,.1))\n",
    "    axes[0,0].grid()\n",
    "    axes[0,1].grid()\n",
    "\n",
    "    axes[1,0].plot(k,preci,marker='o')\n",
    "    axes[1,1].plot(k,recall,marker='o')\n",
    "    axes[1,0].set(title='Precision')\n",
    "    axes[1,1].set(title='Recall')\n",
    "    axes[1,0].set(xlabel='K value')\n",
    "    axes[1,1].set(xlabel='K value')\n",
    "#     axes[1,0].set(xlim=(3,21), ylim=(0,1))\n",
    "#     axes[1,1].set(xlim=(3,21), ylim=(0,1))\n",
    "    axes[1,0].set(xticks=range(3,23,2),yticks=np.arange(0,1.1,.1))\n",
    "    axes[1,1].set(xticks=range(3,23,2),yticks=np.arange(0,1.1,.1))\n",
    "    axes[1,0].grid()\n",
    "    axes[1,1].grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:49.764466Z",
     "start_time": "2019-06-19T02:22:49.737465Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def box_plot_the_metrics(f1_scores,accur,preci,recall):\n",
    "    \"\"\"Box plots for the classification metrics over a range of parameter adjustments\"\"\"\n",
    "    \n",
    "    f=np.asarray(f1_scores)\n",
    "    a=np.asarray(accur)\n",
    "    p=np.asarray(preci)\n",
    "    r=np.asarray(recall)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(20, 10))\n",
    "#     axes.boxplot([f,a,p,r])\n",
    "    axes.boxplot(a)\n",
    "    axes.set_xticklabels(['accuracy'])\n",
    "#     axes.set_xticklabels(['f1_score','accuracy','precision','recall'])\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:49.864472Z",
     "start_time": "2019-06-19T02:22:49.768466Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_of_data_space(dataset,data,labels,input_headers):\n",
    "    \n",
    "    \n",
    "    xx_1=pd.DataFrame(data[:,0]) \n",
    "    xx_2=pd.DataFrame(data[:,1]) \n",
    "    y=pd.DataFrame(labels)\n",
    "    \n",
    "   \n",
    "    plt.figure(figsize=(15,10)) \n",
    "    b=plt.scatter(xx_1[y==0],xx_2[y==0],color='b') \n",
    "    r=plt.scatter(xx_1[y==1],xx_2[y==1],color='r')\n",
    "    g=plt.scatter(xx_1[y==2],xx_2[y==2],color='g') \n",
    "    bl=plt.scatter(xx_1[y==3],xx_2[y==3],color='black')\n",
    "    \n",
    "    \n",
    "#     for i in range(0,len(xx_1)):\n",
    "#         print(y[i])\n",
    "#         if (y[i]==0):\n",
    "#             a=plt.scatter(xx_1[i],xx_2[i],marker='o',color='blue',s=30)\n",
    "#         if (y[i]==1):\n",
    "#             b=plt.scatter(xx_1[i],xx_2[i],marker='o',color='red',s=30)\n",
    "#         if (y[i]==2):\n",
    "#             c=plt.scatter(xx_1[i],xx_2[i],marker='o',color='green',s=30)\n",
    "#         if (y[i]==3):\n",
    "#             d=plt.scatter(xx_1[i],xx_2[i],marker='o',color='black',s=30)\n",
    "        \n",
    "#     plt.xlabel(f1);plt.ylabel(f2);\n",
    "#     plt.legend((a,b),tuple(np.unique(labels)))\n",
    "\n",
    "    plt.xlabel(input_headers[0])\n",
    "    plt.ylabel(input_headers[1])\n",
    "\n",
    "    plt.grid()\n",
    "    plt.legend((b,r,g,bl),tuple(np.unique(labels)))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:50.084484Z",
     "start_time": "2019-06-19T02:22:49.868472Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def boundary_decision_plot(X,y,X_train,y_train,x_test,y_pred,y_prob):\n",
    "    \n",
    "    X_unscaled=X.values\n",
    "    X_scaled, dummy=feature_scaling(X_unscaled,X_test=np.ones((2,2)))\n",
    "    xx_1=pd.DataFrame(X_train[:,0]) \n",
    "    xx_2=pd.DataFrame(X_train[:,1]) \n",
    "    y=pd.DataFrame(y_train.values)\n",
    "    \n",
    "#     print(y_train[0:5])\n",
    "#     print(X_train[0:5])\n",
    "\n",
    "    xx_test_1=pd.DataFrame(x_test[:,0]) \n",
    "    xx_test_2=pd.DataFrame(x_test[:,1])\n",
    "\n",
    "    y_predict=pd.DataFrame(y_pred) \n",
    "    y_prob=pd.DataFrame(y_prob) \n",
    "\n",
    "    cmap_light = ListedColormap(['#FFAAAA','#AAAAFF'])\n",
    "\n",
    "#     cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "    cmap_bold = ListedColormap(['#FF0000','#0000FF'])\n",
    "\n",
    "    h=.02\n",
    "\n",
    "#     Plot the decision boundary. For that, we will assign a color to each point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "#     x1=X_train[:,0] \n",
    "    x1=X_scaled[:,0]\n",
    "    x2=X_scaled[:,1] \n",
    "    x_min,x_max = x1.min()-1,x1.max()+1 \n",
    "    y_min,y_max = x2.min()-1,x2.max()+1 \n",
    "    xx,yy = np.meshgrid(np.arange(x_min,x_max,h),np.arange(y_min,y_max,h))\n",
    "\n",
    "\n",
    "    the_predict=classifier.predict(np.c_[xx.ravel(),yy.ravel()])\n",
    "\n",
    "#     Put the result into a color plot\n",
    "    Z = the_predict.reshape(xx.shape) \n",
    "    plt.figure(figsize=(15,15)) \n",
    "    plt.xlim(xx.min(),xx.max()) \n",
    "    plt.ylim(yy.min(),yy.max())\n",
    "\n",
    "    plt.pcolormesh(xx,yy,Z,cmap=cmap_light)\n",
    "\n",
    "#     plt.scatter(xx_1[y==0],xx_2[y==0],color='b',marker='o') \n",
    "#     plt.scatter(xx_1[y==1],xx_2[y==1],color='r',marker='o')\n",
    "    \n",
    "\n",
    "#     plt.scatter(X_train[:,0],X_train[:,1],s=40,c=y_train,cmap=plt.cm.Spectral)\n",
    "    cm=plt.cm.get_cmap('RdYlBu_r')\n",
    "\n",
    "#     plt.scatter(xx_test_1[y_predict==0],xx_test_2[y_predict==0],cmap=cm,vmin=0,vmax=1,c=y_predict,marker='D') \n",
    "#     plt.scatter(xx_test_1[y_predict==1],xx_test_2[y_predict==1],cmap=cm,vmin=0,vmax=1,c=y_predict,marker='D') \n",
    "    plt.scatter(xx_test_1[y_predict==0],xx_test_2[y_predict==0],cmap=cm,vmin=0,vmax=1,c=y_prob,marker='D') \n",
    "    plt.scatter(xx_test_1[y_predict==1],xx_test_2[y_predict==1],cmap=cm,vmin=0,vmax=1,c=y_prob,marker='D') \n",
    "    plt.colorbar()\n",
    "\n",
    "\n",
    "    plt.grid() \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:50.125487Z",
     "start_time": "2019-06-19T02:22:50.089485Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_results(f1_scores,accur,preci,recall,k):\n",
    "    \n",
    "    f=np.asarray(f1_scores)\n",
    "    a=np.asarray(accur)\n",
    "    p=np.asarray(preci)\n",
    "    r=np.asarray(recall)\n",
    "    k=np.asarray(k)\n",
    "    \n",
    "    results=f\"\"\"\\n\n",
    "    The max F1 SCORE is {round((f.max()*100),1)}% with a K value of {k[np.argmax(f)]}\\n\n",
    "    The max ACCURACY is {round((a.max()*100),1)}% with a K value of {k[np.argmax(a)]}\\n\n",
    "    The max PRECISION is {round((p.max()*100),1)}% with a K value of {k[np.argmax(p)]}\\n\n",
    "    The max RECALL is {round((r.max()*100),1)}% with a K value of {k[np.argmax(r)]}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(results)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:50.161489Z",
     "start_time": "2019-06-19T02:22:50.130487Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_encoding(dataset,input_headers):\n",
    "    \n",
    "    for i in input_headers:\n",
    "        \n",
    "        the_data_type=dataset[i].dtype.name\n",
    "        if (the_data_type=='object'):\n",
    "            lable_enc=preprocessing.LabelEncoder()\n",
    "            lable_enc.fit(dataset[i])\n",
    "            labels=lable_enc.classes_   #this is an array\n",
    "            labels=list(labels) #converting the labels array to a list\n",
    "            print(labels)\n",
    "            dataset[i]=lable_enc.transform(dataset[i])\n",
    "\n",
    "            return labels\n",
    "    \n",
    "        else:\n",
    "            return list(np.unique(dataset[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_program_settings(**kwargs):\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('C:/Users/Crystal/Desktop/Programs/machine_learning/Machine-Learning-Classification-scikit-learn/model_parameters.ini')\n",
    "\n",
    "    if 'model_spec' in kwargs:\n",
    "        print(config[model_spec])\n",
    "        \n",
    "        return config[model_spec]\n",
    "\n",
    "    para=dict()\n",
    "    para['location']=config['Data Select']['data file']\n",
    "    para['dataset report']=config['Report Option']['dataset report']\n",
    "    para['feature report']=config['Report Option']['feature report']\n",
    "    para['selected features']=(config['Data Select']['features']).split(',')\n",
    "    para['target']=config['Data Select']['target']\n",
    "\n",
    "    para['test size']=float(config['Train-Test Data']['test size'])\n",
    "    para['random state']=int(config['Train-Test Data']['random state'])\n",
    "\n",
    "    para['cv']=int(config['Cross Validation']['cv'])\n",
    "\n",
    "\n",
    "\n",
    "    print(para)\n",
    "\n",
    "    return para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_drop(dataset,headers_to_drop):\n",
    "    \n",
    "    dataset.drop(labels=headers_to_drop,axis=1,inplace=True)\n",
    "    dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN PROGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:22:50.226493Z",
     "start_time": "2019-06-19T02:22:50.191491Z"
    },
    "collapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Data Select'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [41], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m      3\u001b[0m     \u001b[39mglobal\u001b[39;00m classifier, classes\n\u001b[0;32m----> 5\u001b[0m     parameters\u001b[39m=\u001b[39mget_program_settings()\n\u001b[1;32m      7\u001b[0m     location\u001b[39m=\u001b[39mparameters[\u001b[39m'\u001b[39m\u001b[39mlocation\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m     dataset\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mread_csv(location)\n",
      "Cell \u001b[0;32mIn [39], line 11\u001b[0m, in \u001b[0;36mget_program_settings\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m config[model_spec]\n\u001b[1;32m     10\u001b[0m para\u001b[39m=\u001b[39m\u001b[39mdict\u001b[39m()\n\u001b[0;32m---> 11\u001b[0m para[\u001b[39m'\u001b[39m\u001b[39mlocation\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39;49m\u001b[39mData Select\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mdata file\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m para[\u001b[39m'\u001b[39m\u001b[39mdataset report\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mReport Option\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mdataset report\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     13\u001b[0m para[\u001b[39m'\u001b[39m\u001b[39mfeature report\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m=\u001b[39mconfig[\u001b[39m'\u001b[39m\u001b[39mReport Option\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mfeature report\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/lib/python3.10/configparser.py:964\u001b[0m, in \u001b[0;36mRawConfigParser.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m    963\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_section \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_section(key):\n\u001b[0;32m--> 964\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m    965\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_proxies[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Data Select'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    global classifier, classes\n",
    "    \n",
    "    parameters=get_program_settings()\n",
    "    \n",
    "    location=parameters['location']\n",
    "    \n",
    "    dataset=pd.read_csv(location)\n",
    "    \n",
    "    dataset.info()\n",
    "    dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if (parameters['dataset report']=='YES'):\n",
    "    dataset_report = ProfileReport(dataset,minimal=True)\n",
    "    dataset_report.to_file(output_file='all_data_eda.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:23:29.662748Z",
     "start_time": "2019-06-19T02:22:50.229493Z"
    }
   },
   "outputs": [],
   "source": [
    "    # Replace zeros with the mean where needed.\n",
    "    # rz=input('Do you need to replace any zeros in the dataset?')\n",
    "    # the_headers=[None]\n",
    "    # if (rz.lower()=='y'):\n",
    "    #     replacing_zeros(dataset,the_headers)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting inputs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols=list(dataset.columns)\n",
    "all_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_target=[]\n",
    "the_target.append(parameters['target'])\n",
    "selected_cols=parameters['selected features']+the_target\n",
    "# selected_cols=['time','ejection_fraction',the_target[0]]\n",
    "selected_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_these=list(set(all_cols).difference(set(selected_cols)))\n",
    "drop_these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_columns=drop_these\n",
    "# if (drop_columns!=[]):\n",
    "#     q1=input('Do you need to drop any columns in the dataset?')\n",
    "#     if (q1.lower()=='y'):\n",
    "#         feature_drop(dataset,drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_header=the_target\n",
    "selected_cols.remove(target_header[0])\n",
    "input_headers=selected_cols\n",
    "print(target_header)\n",
    "print(input_headers)\n",
    "target_label=label_encoding(dataset,target_header)\n",
    "\n",
    "classes=target_label\n",
    "print (classes)\n",
    "test_label=label_encoding(dataset,input_headers)\n",
    "\n",
    "dataset=dataset[input_headers+target_header]\n",
    "X,y=split_the_dataset(dataset,input_headers,target_header)\n",
    "\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Train-Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:23:30.269783Z",
     "start_time": "2019-06-19T02:23:30.259782Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    \n",
    "X_train,X_test,y_train,y_test=split_the_train_test_data(X,y,\n",
    "test_size=parameters['test size'],\n",
    "random_state=parameters['random state'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:23:30.293784Z",
     "start_time": "2019-06-19T02:23:30.275783Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "    X_train, X_test=feature_scaling(X_train,X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call the KNN function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# obtain KNN model parameters from the model_parameters.ini file\n",
    "\n",
    "knn_para=get_program_settings(model_spec='KNN Parameters')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:23:34.814043Z",
     "start_time": "2019-06-19T02:23:30.299785Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "    # list_or_single=input('(S)ingle or (R)ange of k-values? ')\n",
    "    list_or_single=knn_para.get('K range')\n",
    "    k=select_k_value(y_test,list_or_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:23:38.841273Z",
     "start_time": "2019-06-19T02:23:34.817043Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "    f1_scores,accur,preci,recall,y_pred,y_prob=KNN(k,X_train,y_train,X_test,y_test)\n",
    "    print(y_pred)\n",
    "    print(y_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:23:40.182350Z",
     "start_time": "2019-06-19T02:23:38.846273Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    \n",
    "    plot_the_metrics(f1_scores,accur,preci,recall)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:23:40.614375Z",
     "start_time": "2019-06-19T02:23:40.186350Z"
    }
   },
   "outputs": [],
   "source": [
    "    #Box plot of the metrics\n",
    "    box_plot_the_metrics(f1_scores,accur,preci,recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Score Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:23:40.624375Z",
     "start_time": "2019-06-19T02:23:40.617375Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_results(f1_scores,accur,preci,recall,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Plot the decision boundaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-19T02:23:43.379533Z",
     "start_time": "2019-06-19T02:23:40.628375Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "    if (X.values.shape[1]==2):\n",
    "        boundary_decision_plot(X,y,X_train,y_train,X_test,y_pred,y_prob)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "35px",
    "width": "292px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "272px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "463px",
    "left": "895px",
    "right": "20px",
    "top": "59px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
